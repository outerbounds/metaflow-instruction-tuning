training:
  num_epochs: 1
  macro_batch_size: 1
  visible_devices: null
  world_size: 2
  cutoff_len: 258
  micro_batch_size: 1
  model_save_directory: ./lora-alpaca
  master_port: 1234
  fp16: false
model:
  base_model: yahma/llama-7b-hf
lora:
  r: 2
  target_modules: '[q_proj,v_proj]'
dataset:
  num_data_samples: 500
  dataset_path: yahma/alpaca-cleaned
  prompt_template:
    description: Template used by Alpaca-LoRA.
    prompt_input: 'Below is an instruction that describes a task, paired with an input
      that provides further context. Write a response that appropriately completes
      the request.

      ### Instruction:

      {instruction}

      ### Input:

      {input}

      ### Response:

      '
    prompt_no_input: 'Below is an instruction that describes a task. Write a response
      that appropriately completes the request.

      ### Instruction:

      {instruction}

      ### Response:

      '
    response_split: '### Response:'
